# Robots.txt for GamblingReviews.com
# This file tells search engines which pages to crawl and which to avoid

User-agent: *
Allow: /

# Allow crawling of main content areas
Allow: /css/
Allow: /js/
Allow: /images/
Allow: /reviews/
Allow: /casinos/
Allow: /sportsbooks/
Allow: /blog/
Allow: /guides/

# Disallow admin and sensitive areas
Disallow: /admin/
Disallow: /admin/*
Disallow: /data/
Disallow: /config/
Disallow: /includes/
Disallow: /private/
Disallow: /temp/
Disallow: /tmp/
Disallow: /cache/
Disallow: /backup/
Disallow: /backups/
Disallow: /logs/
Disallow: /log/

# Disallow search and filtering pages that might create duplicate content
Disallow: /search?
Disallow: /search/
Disallow: /*?sort=
Disallow: /*?filter=
Disallow: /*?page=
Disallow: /*?utm_*
Disallow: /*?ref=
Disallow: /*?referral=

# Disallow common WordPress/CMS paths (if applicable)
Disallow: /wp-admin/
Disallow: /wp-includes/
Disallow: /wp-content/plugins/
Disallow: /wp-content/themes/
Disallow: /wp-content/cache/
Disallow: /xmlrpc.php
Disallow: /wp-login.php
Disallow: /wp-register.php

# Disallow file types that shouldn't be indexed
Disallow: /*.pdf$
Disallow: /*.doc$
Disallow: /*.docx$
Disallow: /*.xls$
Disallow: /*.xlsx$
Disallow: /*.ppt$
Disallow: /*.pptx$
Disallow: /*.zip$
Disallow: /*.rar$
Disallow: /*.exe$
Disallow: /*.dmg$

# Disallow printer-friendly and mobile versions if they exist
Disallow: /print/
Disallow: /mobile/
Disallow: /*?print=
Disallow: /*?mobile=

# Disallow tracking and analytics pages
Disallow: /analytics/
Disallow: /stats/
Disallow: /tracking/

# Special rules for specific bots
User-agent: Googlebot
Allow: /
Crawl-delay: 1

User-agent: Bingbot
Allow: /
Crawl-delay: 1

User-agent: Slurp
Allow: /
Crawl-delay: 2

User-agent: DuckDuckBot
Allow: /
Crawl-delay: 1

User-agent: Baiduspider
Allow: /
Crawl-delay: 2

User-agent: YandexBot
Allow: /
Crawl-delay: 2

User-agent: facebookexternalhit
Allow: /
Crawl-delay: 1

User-agent: Twitterbot
Allow: /

User-agent: LinkedInBot
Allow: /

# Block aggressive crawlers and scrapers
User-agent: SemrushBot
Crawl-delay: 10

User-agent: AhrefsBot
Crawl-delay: 10

User-agent: MJ12bot
Crawl-delay: 10

User-agent: DotBot
Crawl-delay: 10

User-agent: PetalBot
Crawl-delay: 10

# Block bad bots and scrapers
User-agent: ia_archiver
Disallow: /

User-agent: ScoutJet
Disallow: /

User-agent: WebCopier
Disallow: /

User-agent: HTTrack
Disallow: /

User-agent: Teleport
Disallow: /

User-agent: TeleportPro
Disallow: /

User-agent: MIMEfind
Disallow: /

User-agent: Zeus
Disallow: /

User-agent: RepoMonkey
Disallow: /

User-agent: Copier
Disallow: /

User-agent: Offline Explorer
Disallow: /

User-agent: Telesoft
Disallow: /

User-agent: Website Quester
Disallow: /

User-agent: moget/2.1
Disallow: /

User-agent: WebZip/4.0
Disallow: /

User-agent: WebStripper
Disallow: /

User-agent: WebSauger
Disallow: /

User-agent: WebCopier v3.0
Disallow: /

User-agent: NetAnts
Disallow: /

User-agent: Mister PiX
Disallow: /

User-agent: WebAuto
Disallow: /

User-agent: TheNomad
Disallow: /

User-agent: WWW-Collector-E
Disallow: /

User-agent: RMA
Disallow: /

User-agent: libWeb/clsHTTP
Disallow: /

User-agent: asterias
Disallow: /

User-agent: httplib
Disallow: /

User-agent: turingos
Disallow: /

User-agent: spanner
Disallow: /

User-agent: InfoNaviRobot
Disallow: /

User-agent: Harvest/1.5
Disallow: /

User-agent: Bullseye/1.0
Disallow: /

User-agent: Mozilla/4.0 (compatible; BullsEye; Windows 95)
Disallow: /

User-agent: Crescent Internet ToolPak HTTP OLE Control v.1.0
Disallow: /

User-agent: CherryPickerSE/1.0
Disallow: /

User-agent: CherryPickerElite/1.0
Disallow: /

User-agent: WebBandit/3.50
Disallow: /

User-agent: NICErsPRO
Disallow: /

User-agent: Microsoft URL Control - 5.01.4511
Disallow: /

User-agent: DittoSpyder
Disallow: /

User-agent: Foobot
Disallow: /

User-agent: WebmasterWorldForumBot
Disallow: /

User-agent: SpankBot
Disallow: /

User-agent: BotALot
Disallow: /

User-agent: lwp-trivial/1.34
Disallow: /

User-agent: lwp-trivial
Disallow: /

User-agent: BunnySlippers
Disallow: /

User-agent: Microsoft URL Control - 6.00.8169
Disallow: /

User-agent: URLy Warning
Disallow: /

User-agent: Wget/1.6
Disallow: /

User-agent: Wget/1.5.3
Disallow: /

User-agent: Wget
Disallow: /

User-agent: LinkWalker
Disallow: /

User-agent: cosmos
Disallow: /

User-agent: moget
Disallow: /

User-agent: hloader
Disallow: /

User-agent: humanlinks
Disallow: /

User-agent: LinkextractorPro
Disallow: /

User-agent: Offline Explorer
Disallow: /

User-agent: Mata Hari
Disallow: /

User-agent: LexiBot
Disallow: /

User-agent: Web Image Collector
Disallow: /

User-agent: The Intraformant
Disallow: /

User-agent: True_Robot/1.0
Disallow: /

User-agent: True_Robot
Disallow: /

User-agent: BlowFish/1.0
Disallow: /

User-agent: JennyBot
Disallow: /

User-agent: MIIxpc/4.2
Disallow: /

User-agent: BuiltBotTough
Disallow: /

User-agent: ProPowerBot/2.14
Disallow: /

User-agent: BackDoorBot/1.0
Disallow: /

User-agent: toCrawl/UrlDispatcher
Disallow: /

User-agent: WebEnhancer
Disallow: /

User-agent: suzuran
Disallow: /

User-agent: VoidEYE
Disallow: /

User-agent: Cyclone
Disallow: /

User-agent: UtilMind HTTPGet
Disallow: /

User-agent: navroad
Disallow: /

User-agent: Snappy
Disallow: /

User-agent: GetRight/4.2
Disallow: /

User-agent: SiteSnagger
Disallow: /

User-agent: GetWeb!
Disallow: /

User-agent: Go!Zilla
Disallow: /

User-agent: Go-Ahead-Got-It
Disallow: /

User-agent: Go!Zilla 4.0
Disallow: /

User-agent: Slurp
Disallow: /

# Sitemaps
Sitemap: https://gamblingreviews.com/sitemap.xml
Sitemap: https://gamblingreviews.com/sitemap-reviews.xml
Sitemap: https://gamblingreviews.com/sitemap-blog.xml
Sitemap: https://gamblingreviews.com/sitemap-guides.xml

# Host directive (helps with canonicalization)
Host: https://gamblingreviews.com